{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Preprocessing.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gep4rpYo1M59",
        "colab_type": "text"
      },
      "source": [
        "# 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvTfKrPK1M5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMq7ls4J1M6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_IN_PATH = r'/data_in/'\n",
        "\n",
        "train_data = pd.read_csv(DATA_IN_PATH+'ratings_train.txt', delimiter='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATixHDIN1M6F",
        "colab_type": "code",
        "colab": {},
        "outputId": "2bf98664-9788-4eac-bc9a-fb277a435f7b"
      },
      "source": [
        "train_data['document'][:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                  아 더빙.. 진짜 짜증나네요 목소리\n",
              "1                    흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
              "2                                    너무재밓었다그래서보는것을추천한다\n",
              "3                        교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
              "4    사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...\n",
              "Name: document, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8hLIIzk1M6K",
        "colab_type": "code",
        "colab": {},
        "outputId": "1f1d1c50-e5c9-4ca3-81d2-291b906ef6ae"
      },
      "source": [
        "train_data['document'].isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5V6wVeA1M6P",
        "colab_type": "code",
        "colab": {},
        "outputId": "17e076f9-cb3a-42a7-e99e-768332975937"
      },
      "source": [
        "# 특수문자 혹은 숫자 제거\n",
        "review_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", train_data['document'][0])\n",
        "print(review_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "아 더빙 진짜 짜증나네요 목소리\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w98Avf6e1M6S",
        "colab_type": "code",
        "colab": {},
        "outputId": "31519fe8-28b2-42a5-9dfd-00c31f94ef84"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "okt = Okt()\n",
        "review_text = okt.morphs(review_text, stem=True)\n",
        "print(review_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['아', '더빙', '진짜', '짜증나다', '목소리']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCIyYAXN1M6W",
        "colab_type": "code",
        "colab": {},
        "outputId": "f64e6d30-5887-4b54-fe70-fa9a89c01cf0"
      },
      "source": [
        "# 불용어 제거\n",
        "\n",
        "stop_words = set(['은', '는', '이', '가', '하', '아', '것', '들', '의', '있', '되', '수', '보', '주', '등', '한'])\n",
        "\n",
        "clean_review = [token for token in review_text if not token in stop_words]\n",
        "print(clean_review)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['더빙', '진짜', '짜증나다', '목소리']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCkKxq441M6Z",
        "colab_type": "text"
      },
      "source": [
        "# 전처리 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwEhwaAK1M6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(review, okt, remove_stopwords=False, stop_words=[]):\n",
        "    # review : 전처리할 텍스트\n",
        "    # okt : okt 객체를 반복적으로 생성하지 않고 미리 생성한 후 인자로 받는다.\n",
        "    # remove_stopwords : 불용어를 제거할지 여부 선택, 기본값은 False\n",
        "    # stop_word : 불용어 사전은 사용자가 직접 입력해야 함. 기본값은 빈 리스트\n",
        "    \n",
        "    # 1. 한글 및 공백을 제외한 문자를 모두 제거\n",
        "    review_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", review)\n",
        "    \n",
        "    # 2. okt 객체를 활용해 형태소 단위로 나눈다\n",
        "    word_review = okt.morphs(review_text, stem=True)\n",
        "    \n",
        "    if remove_stopwords:\n",
        "        word_review = [token for token in word_review if not token in stop_words]\n",
        "    \n",
        "    return word_review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUXwOH7t1M6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(['은', '는', '이', '가', '하', '아', '것', '들', '의', '있', '되', '수', '보', '주', '등', '한'])\n",
        "okt = Okt()\n",
        "clean_train_review = []\n",
        "\n",
        "for review in train_data['document']:\n",
        "    # 비어있는 데이터에서 멈추지 않도록 문자열인 경우에만 진행\n",
        "    if type(review) == str:\n",
        "        clean_train_review.append(preprocessing(review, okt, remove_stopwords=True, stop_words=stop_words))\n",
        "    else:\n",
        "        clean_train_review.append([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP_VjU6u1M6f",
        "colab_type": "code",
        "colab": {},
        "outputId": "1fe4f54e-0064-4abe-aaa0-b43678e2073c"
      },
      "source": [
        "clean_train_review[:4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['더빙', '진짜', '짜증나다', '목소리'],\n",
              " ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍다', '않다'],\n",
              " ['너', '무재', '밓었', '다그', '래서', '보다', '추천', '다'],\n",
              " ['교도소', '이야기', '구먼', '솔직하다', '재미', '없다', '평점', '조정']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnrCchMv1M6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 평가데이터도 똑같이 전처리\n",
        "test_data = pd.read_csv(DATA_IN_PATH + 'ratings_test.txt', delimiter='\\t')\n",
        "\n",
        "clean_test_review=[]\n",
        "\n",
        "for review in test_data['document']:\n",
        "    if type(review) == str:\n",
        "        clean_test_review.append(preprocessing(review, okt, remove_stopwords=True, stop_words=stop_words))\n",
        "    else:\n",
        "        clean_test_review.append([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So2DCXDx1M6n",
        "colab_type": "text"
      },
      "source": [
        "# 인덱스 벡터로 변환과 패딩 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wonWlLMG1M6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(clean_train_review)\n",
        "word_vocab = tokenizer.word_index\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(clean_train_review)\n",
        "test_sequences = tokenizer.texts_to_sequences(clean_test_review)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjV1w7GO1M6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 8 # 문장 최대 길이\n",
        "\n",
        "train_inputs = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "train_labels = np.array(train_data['label'])\n",
        "\n",
        "test_inputs = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "test_labels = np.array(test_data['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4JFyH6l1M6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "clean_train_df = pd.DataFrame({'document': clean_train_review, 'label': train_data['label']})\n",
        "clean_test_df = pd.DataFrame({'document': clean_test_review, 'label': test_data['label']})\n",
        "\n",
        "data_configs = {}\n",
        "data_configs['vocab'] = word_vocab\n",
        "data_configs['vocab_size'] = len(word_vocab)\n",
        "\n",
        "if not os.path.exists(DATA_IN_PATH):\n",
        "    os.makedirs(DATA_IN_PATH)\n",
        "\n",
        "# 전처리된 학습 데이터를 넘파이 형태로 저장\n",
        "np.save(open(DATA_IN_PATH+'nsmc_train_input.npy', 'wb'), train_inputs)\n",
        "np.save(open(DATA_IN_PATH+'nsmc_train_label.npy', 'wb'), train_labels)\n",
        "\n",
        "# 전처리된 평가 데이터를 넘파이 형태로 저장\n",
        "np.save(open(DATA_IN_PATH+'nsmc_test_input.npy', 'wb'), test_inputs)\n",
        "np.save(open(DATA_IN_PATH+'nsmc_test_label.npy', 'wb'), test_labels)\n",
        "\n",
        "# 정제된 데이터를 csv 형태로 저장\n",
        "clean_train_df.to_csv(DATA_IN_PATH+'nsmc_train_clean.csv', index=False)\n",
        "clean_test_df.to_csv(DATA_IN_PATH+'nsmc_test_clean.csv', index=False)\n",
        "\n",
        "# 데이터 사전을 json 형태로 저장\n",
        "json.dump(data_configs, open(DATA_IN_PATH+'data_configs.json', 'w'), ensure_ascii=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}